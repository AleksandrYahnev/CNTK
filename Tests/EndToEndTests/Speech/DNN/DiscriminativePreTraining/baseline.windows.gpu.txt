CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 268381192 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-SlaveTest/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/cntk_dpt.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta4.0+ (HEAD 4e00f7, Nov 22 2016 22:04:50) on DPHAIM-22 at 2016/11/23 08:05:13

C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/cntk_dpt.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data
11/23/2016 08:05:15: -------------------------------------------------------------------
11/23/2016 08:05:15: Build info: 

11/23/2016 08:05:15: 		Built time: Nov 22 2016 22:04:50
11/23/2016 08:05:15: 		Last modified date: Tue Nov 22 11:27:04 2016
11/23/2016 08:05:15: 		Build type: Release
11/23/2016 08:05:15: 		Build target: GPU
11/23/2016 08:05:15: 		With 1bit-SGD: no
11/23/2016 08:05:15: 		With ASGD: yes
11/23/2016 08:05:15: 		Math lib: mkl
11/23/2016 08:05:15: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
11/23/2016 08:05:15: 		CUB_PATH: c:\src\cub-1.4.1
11/23/2016 08:05:15: 		CUDNN_PATH: c:\NVIDIA\cudnn-5.1\cuda
11/23/2016 08:05:15: 		Build Branch: HEAD
11/23/2016 08:05:15: 		Build SHA1: 4e00f7dcce1ff2ca55227cc35b49ef5ed065fd1a (modified)
11/23/2016 08:05:15: 		Built by svcphil on LIANA-09-w
11/23/2016 08:05:15: 		Build Path: C:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
11/23/2016 08:05:15: -------------------------------------------------------------------
11/23/2016 08:05:16: -------------------------------------------------------------------
11/23/2016 08:05:16: GPU info:

11/23/2016 08:05:16: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
11/23/2016 08:05:16: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
11/23/2016 08:05:16: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_dpt.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:addLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
configparameters: cntk_dpt.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining
configparameters: cntk_dpt.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data
configparameters: cntk_dpt.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data
configparameters: cntk_dpt.cntk:deviceId=0
configparameters: cntk_dpt.cntk:dptPre1=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:dptPre2=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_dpt.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_dpt.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_dpt.cntk:ndlMacros=C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/macros.txt
configparameters: cntk_dpt.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:precision=double
configparameters: cntk_dpt.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp"
    ]
    labels = [
        mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
        labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_dpt.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_dpt.cntk:speechTrain=[
    action = "train"
    modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech"
    deviceId = 0
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\DNN\DiscriminativePreTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_dpt.cntk:timestamping=true
configparameters: cntk_dpt.cntk:traceLevel=1
11/23/2016 08:05:16: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain
11/23/2016 08:05:16: precision = "double"

11/23/2016 08:05:16: ##############################################################################
11/23/2016 08:05:16: #                                                                            #
11/23/2016 08:05:16: # dptPre1 command (train action)                                             #
11/23/2016 08:05:16: #                                                                            #
11/23/2016 08:05:16: ##############################################################################

11/23/2016 08:05:16: 
Creating virgin network.
NDLBuilder Using GPU 0
Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
reading script file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/23/2016 08:05:18: 
Model has 19 nodes. Using GPU 0.

11/23/2016 08:05:18: Training criterion:   ce = CrossEntropyWithSoftmax
11/23/2016 08:05:18: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }


11/23/2016 08:05:18: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

11/23/2016 08:05:18: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/23/2016 08:05:18: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/23/2016 08:05:18: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/23/2016 08:05:18: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/23/2016 08:05:18: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/23/2016 08:05:18: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/23/2016 08:05:19: Starting minibatch loop.
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.77719393 * 2560; err = 0.84648437 * 2560; time = 0.3744s; samplesPerSecond = 6837.5
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.91575657 * 2560; err = 0.69960937 * 2560; time = 0.0440s; samplesPerSecond = 58143.5
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.53429712 * 2560; err = 0.64570313 * 2560; time = 0.0441s; samplesPerSecond = 58022.3
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.16117988 * 2560; err = 0.57734375 * 2560; time = 0.0441s; samplesPerSecond = 57997.3
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.92699082 * 2560; err = 0.53828125 * 2560; time = 0.0429s; samplesPerSecond = 59622.2
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.84277261 * 2560; err = 0.49765625 * 2560; time = 0.0407s; samplesPerSecond = 62848.3
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.81774933 * 2560; err = 0.51718750 * 2560; time = 0.0407s; samplesPerSecond = 62832.9
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.71848541 * 2560; err = 0.49101563 * 2560; time = 0.0407s; samplesPerSecond = 62856.0
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.64970714 * 2560; err = 0.46484375 * 2560; time = 0.0411s; samplesPerSecond = 62272.0
11/23/2016 08:05:19:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.56676114 * 2560; err = 0.45703125 * 2560; time = 0.0398s; samplesPerSecond = 64349.1
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.62037813 * 2560; err = 0.46054688 * 2560; time = 0.0398s; samplesPerSecond = 64284.5
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.55446653 * 2560; err = 0.44570312 * 2560; time = 0.0399s; samplesPerSecond = 64107.4
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.51417682 * 2560; err = 0.44804688 * 2560; time = 0.0399s; samplesPerSecond = 64133.1
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.52414181 * 2560; err = 0.46093750 * 2560; time = 0.0398s; samplesPerSecond = 64263.5
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.45795034 * 2560; err = 0.42851563 * 2560; time = 0.0398s; samplesPerSecond = 64357.2
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43940305 * 2560; err = 0.43632813 * 2560; time = 0.0398s; samplesPerSecond = 64308.7
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.43289645 * 2560; err = 0.41835937 * 2560; time = 0.0398s; samplesPerSecond = 64347.5
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.38134805 * 2560; err = 0.40781250 * 2560; time = 0.0398s; samplesPerSecond = 64257.0
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.35088485 * 2560; err = 0.40351562 * 2560; time = 0.0399s; samplesPerSecond = 64178.1
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.40542350 * 2560; err = 0.41171875 * 2560; time = 0.0397s; samplesPerSecond = 64465.8
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.39178206 * 2560; err = 0.40429688 * 2560; time = 0.0398s; samplesPerSecond = 64292.5
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.38929946 * 2560; err = 0.41406250 * 2560; time = 0.0398s; samplesPerSecond = 64399.3
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.32810129 * 2560; err = 0.39609375 * 2560; time = 0.0399s; samplesPerSecond = 64202.2
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.36189859 * 2560; err = 0.40781250 * 2560; time = 0.0398s; samplesPerSecond = 64250.6
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.30827373 * 2560; err = 0.39570312 * 2560; time = 0.0398s; samplesPerSecond = 64278.0
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.25254246 * 2560; err = 0.37304688 * 2560; time = 0.0398s; samplesPerSecond = 64362.0
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.31211297 * 2560; err = 0.40585938 * 2560; time = 0.0397s; samplesPerSecond = 64483.6
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.36173999 * 2560; err = 0.41210938 * 2560; time = 0.0398s; samplesPerSecond = 64320.0
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.29248758 * 2560; err = 0.39140625 * 2560; time = 0.0397s; samplesPerSecond = 64517.8
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.36509678 * 2560; err = 0.41445312 * 2560; time = 0.0397s; samplesPerSecond = 64449.5
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.36516512 * 2560; err = 0.40820313 * 2560; time = 0.0397s; samplesPerSecond = 64420.3
11/23/2016 08:05:20:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.27258248 * 2560; err = 0.38125000 * 2560; time = 0.0398s; samplesPerSecond = 64265.1
11/23/2016 08:05:20: Finished Epoch[ 1 of 2]: [Training] ce = 1.64353269 * 81920; err = 0.46440430 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=2.77413s
11/23/2016 08:05:20: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech.1'

11/23/2016 08:05:20: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/23/2016 08:05:20: Starting minibatch loop.
11/23/2016 08:05:20:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.25788433 * 2560; err = 0.39023438 * 2560; time = 0.0408s; samplesPerSecond = 62671.4
11/23/2016 08:05:20:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.23613406 * 2560; err = 0.36289063 * 2560; time = 0.0398s; samplesPerSecond = 64260.3
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.24592311 * 2560; err = 0.38671875 * 2560; time = 0.0398s; samplesPerSecond = 64329.7
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.25404088 * 2560; err = 0.38984375 * 2560; time = 0.0398s; samplesPerSecond = 64271.5
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.27653856 * 2560; err = 0.38945313 * 2560; time = 0.0399s; samplesPerSecond = 64081.7
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.18791125 * 2560; err = 0.35937500 * 2560; time = 0.0398s; samplesPerSecond = 64299.0
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.20921986 * 2560; err = 0.37890625 * 2560; time = 0.0399s; samplesPerSecond = 64147.5
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.25199817 * 2560; err = 0.37929687 * 2560; time = 0.0398s; samplesPerSecond = 64396.0
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.28160966 * 2560; err = 0.38828125 * 2560; time = 0.0398s; samplesPerSecond = 64289.3
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.25847501 * 2560; err = 0.38398437 * 2560; time = 0.0399s; samplesPerSecond = 64168.4
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.21947254 * 2560; err = 0.36835937 * 2560; time = 0.0398s; samplesPerSecond = 64315.1
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.19433250 * 2560; err = 0.36171875 * 2560; time = 0.0398s; samplesPerSecond = 64255.4
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.17651996 * 2560; err = 0.36523438 * 2560; time = 0.0398s; samplesPerSecond = 64360.4
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16602647 * 2560; err = 0.35820313 * 2560; time = 0.0398s; samplesPerSecond = 64315.1
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.15104102 * 2560; err = 0.35351563 * 2560; time = 0.0398s; samplesPerSecond = 64326.5
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.13611042 * 2560; err = 0.35781250 * 2560; time = 0.0398s; samplesPerSecond = 64307.1
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.18424970 * 2560; err = 0.35507813 * 2560; time = 0.0399s; samplesPerSecond = 64134.7
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.15006446 * 2560; err = 0.35585937 * 2560; time = 0.0395s; samplesPerSecond = 64746.2
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.16356617 * 2560; err = 0.36054687 * 2560; time = 0.0394s; samplesPerSecond = 64905.4
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11796663 * 2560; err = 0.33710937 * 2560; time = 0.0397s; samplesPerSecond = 64478.8
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.17221558 * 2560; err = 0.34765625 * 2560; time = 0.0397s; samplesPerSecond = 64444.7
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.15886512 * 2560; err = 0.35507813 * 2560; time = 0.0397s; samplesPerSecond = 64537.3
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.09145907 * 2560; err = 0.34453125 * 2560; time = 0.0398s; samplesPerSecond = 64371.7
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.11781145 * 2560; err = 0.34843750 * 2560; time = 0.0397s; samplesPerSecond = 64418.7
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.09223328 * 2560; err = 0.33359375 * 2560; time = 0.0397s; samplesPerSecond = 64447.9
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08386283 * 2560; err = 0.32460937 * 2560; time = 0.0398s; samplesPerSecond = 64331.3
11/23/2016 08:05:21:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.11645616 * 2560; err = 0.34492187 * 2560; time = 0.0398s; samplesPerSecond = 64260.3
11/23/2016 08:05:22:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.11475209 * 2560; err = 0.33789063 * 2560; time = 0.0398s; samplesPerSecond = 64310.3
11/23/2016 08:05:22:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.11373502 * 2560; err = 0.35390625 * 2560; time = 0.0398s; samplesPerSecond = 64355.6
11/23/2016 08:05:22:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08247353 * 2560; err = 0.33085938 * 2560; time = 0.0399s; samplesPerSecond = 64097.7
11/23/2016 08:05:22:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.07610760 * 2560; err = 0.34140625 * 2560; time = 0.0398s; samplesPerSecond = 64370.1
11/23/2016 08:05:22:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06540621 * 2560; err = 0.32734375 * 2560; time = 0.0398s; samplesPerSecond = 64261.9
11/23/2016 08:05:22: Finished Epoch[ 2 of 2]: [Training] ce = 1.16888946 * 81920; err = 0.35852051 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=1.27689s
11/23/2016 08:05:22: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech'

11/23/2016 08:05:22: Action "train" complete.


11/23/2016 08:05:22: ##############################################################################
11/23/2016 08:05:22: #                                                                            #
11/23/2016 08:05:22: # addLayer2 command (edit action)                                            #
11/23/2016 08:05:22: #                                                                            #
11/23/2016 08:05:22: ##############################################################################


11/23/2016 08:05:22: Action "edit" complete.


11/23/2016 08:05:22: ##############################################################################
11/23/2016 08:05:22: #                                                                            #
11/23/2016 08:05:22: # dptPre2 command (train action)                                             #
11/23/2016 08:05:22: #                                                                            #
11/23/2016 08:05:22: ##############################################################################

11/23/2016 08:05:22: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/23/2016 08:05:22: 
Model has 24 nodes. Using GPU 0.

11/23/2016 08:05:22: Training criterion:   ce = CrossEntropyWithSoftmax
11/23/2016 08:05:22: Evaluation criterion: err = ClassificationError

11/23/2016 08:05:22: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

11/23/2016 08:05:22: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/23/2016 08:05:22: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/23/2016 08:05:22: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/23/2016 08:05:22: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/23/2016 08:05:22: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/23/2016 08:05:22: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/23/2016 08:05:22: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/23/2016 08:05:22: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/23/2016 08:05:22: Starting minibatch loop.
11/23/2016 08:05:22:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.13%]: ce = 3.80017125 * 2560; err = 0.81250000 * 2560; time = 0.0929s; samplesPerSecond = 27560.1
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.51228172 * 2560; err = 0.61601562 * 2560; time = 0.0814s; samplesPerSecond = 31435.7
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.10963807 * 2560; err = 0.56992188 * 2560; time = 0.0816s; samplesPerSecond = 31354.9
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.76183626 * 2560; err = 0.48789063 * 2560; time = 0.0773s; samplesPerSecond = 33134.9
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.59858779 * 2560; err = 0.46367188 * 2560; time = 0.0744s; samplesPerSecond = 34423.4
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.55943552 * 2560; err = 0.44179687 * 2560; time = 0.0738s; samplesPerSecond = 34691.6
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.54710988 * 2560; err = 0.45390625 * 2560; time = 0.0727s; samplesPerSecond = 35234.0
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.47505473 * 2560; err = 0.43281250 * 2560; time = 0.0725s; samplesPerSecond = 35325.0
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.43432497 * 2560; err = 0.41679688 * 2560; time = 0.0725s; samplesPerSecond = 35325.9
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.37702950 * 2560; err = 0.40273437 * 2560; time = 0.0723s; samplesPerSecond = 35390.4
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.40971283 * 2560; err = 0.40234375 * 2560; time = 0.0723s; samplesPerSecond = 35384.0
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.35987402 * 2560; err = 0.39453125 * 2560; time = 0.0726s; samplesPerSecond = 35271.9
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.31999710 * 2560; err = 0.39453125 * 2560; time = 0.0727s; samplesPerSecond = 35235.0
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.32421086 * 2560; err = 0.40195313 * 2560; time = 0.0725s; samplesPerSecond = 35292.8
11/23/2016 08:05:23:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.28051583 * 2560; err = 0.38046875 * 2560; time = 0.0725s; samplesPerSecond = 35324.0
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28667916 * 2560; err = 0.38789062 * 2560; time = 0.0726s; samplesPerSecond = 35285.0
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.28133841 * 2560; err = 0.37382813 * 2560; time = 0.0726s; samplesPerSecond = 35247.1
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.25581704 * 2560; err = 0.37812500 * 2560; time = 0.0725s; samplesPerSecond = 35316.7
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.27156672 * 2560; err = 0.38710937 * 2560; time = 0.0725s; samplesPerSecond = 35305.5
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.33206227 * 2560; err = 0.40312500 * 2560; time = 0.0725s; samplesPerSecond = 35297.2
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.31520743 * 2560; err = 0.38906250 * 2560; time = 0.0725s; samplesPerSecond = 35320.6
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.31654786 * 2560; err = 0.40234375 * 2560; time = 0.0725s; samplesPerSecond = 35326.9
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.25409736 * 2560; err = 0.37460938 * 2560; time = 0.0723s; samplesPerSecond = 35389.9
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.27450676 * 2560; err = 0.37773438 * 2560; time = 0.0723s; samplesPerSecond = 35398.2
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.22965499 * 2560; err = 0.36484375 * 2560; time = 0.0724s; samplesPerSecond = 35368.4
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.18720605 * 2560; err = 0.35234375 * 2560; time = 0.0726s; samplesPerSecond = 35279.2
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.20729373 * 2560; err = 0.37656250 * 2560; time = 0.0724s; samplesPerSecond = 35367.9
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.24497052 * 2560; err = 0.37031250 * 2560; time = 0.0726s; samplesPerSecond = 35283.1
11/23/2016 08:05:24:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.17650163 * 2560; err = 0.34257813 * 2560; time = 0.0725s; samplesPerSecond = 35312.8
11/23/2016 08:05:25:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.18264261 * 2560; err = 0.35898438 * 2560; time = 0.0725s; samplesPerSecond = 35310.8
11/23/2016 08:05:25:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.19820382 * 2560; err = 0.35898438 * 2560; time = 0.0725s; samplesPerSecond = 35308.9
11/23/2016 08:05:25:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.16705941 * 2560; err = 0.34921875 * 2560; time = 0.0726s; samplesPerSecond = 35255.9
11/23/2016 08:05:25: Finished Epoch[ 1 of 2]: [Training] ce = 1.47034800 * 81920; err = 0.41936035 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=2.52072s
11/23/2016 08:05:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.1'

11/23/2016 08:05:25: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/23/2016 08:05:25: Starting minibatch loop.
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.13%]: ce = 1.17457346 * 2560; err = 0.36914063 * 2560; time = 0.0735s; samplesPerSecond = 34820.0
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.19164836 * 2560; err = 0.36914063 * 2560; time = 0.0726s; samplesPerSecond = 35266.1
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15207640 * 2560; err = 0.35351563 * 2560; time = 0.0725s; samplesPerSecond = 35298.7
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.14624173 * 2560; err = 0.34726563 * 2560; time = 0.0725s; samplesPerSecond = 35307.9
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.63%]: ce = 1.19112246 * 2560; err = 0.35156250 * 2560; time = 0.0724s; samplesPerSecond = 35364.5
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.12421143 * 2560; err = 0.34648438 * 2560; time = 0.0723s; samplesPerSecond = 35408.5
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14073056 * 2560; err = 0.35664062 * 2560; time = 0.0724s; samplesPerSecond = 35357.2
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.16855203 * 2560; err = 0.35703125 * 2560; time = 0.0725s; samplesPerSecond = 35313.8
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.13%]: ce = 1.17332665 * 2560; err = 0.36718750 * 2560; time = 0.0724s; samplesPerSecond = 35341.5
11/23/2016 08:05:25:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18124638 * 2560; err = 0.34648438 * 2560; time = 0.0725s; samplesPerSecond = 35297.2
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.13891543 * 2560; err = 0.33945313 * 2560; time = 0.0725s; samplesPerSecond = 35294.3
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13162320 * 2560; err = 0.34843750 * 2560; time = 0.0725s; samplesPerSecond = 35309.9
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.63%]: ce = 1.10221718 * 2560; err = 0.34687500 * 2560; time = 0.0727s; samplesPerSecond = 35225.3
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.12756891 * 2560; err = 0.34648438 * 2560; time = 0.0725s; samplesPerSecond = 35311.3
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.09651537 * 2560; err = 0.33750000 * 2560; time = 0.0725s; samplesPerSecond = 35332.8
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.07616066 * 2560; err = 0.34218750 * 2560; time = 0.0725s; samplesPerSecond = 35330.8
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.13%]: ce = 1.11689008 * 2560; err = 0.32851562 * 2560; time = 0.0725s; samplesPerSecond = 35331.8
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.08350884 * 2560; err = 0.33281250 * 2560; time = 0.0725s; samplesPerSecond = 35296.7
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11601200 * 2560; err = 0.35195312 * 2560; time = 0.0723s; samplesPerSecond = 35395.8
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.07885517 * 2560; err = 0.33125000 * 2560; time = 0.0723s; samplesPerSecond = 35407.0
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.63%]: ce = 1.12037443 * 2560; err = 0.32968750 * 2560; time = 0.0724s; samplesPerSecond = 35352.8
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.10189620 * 2560; err = 0.33632812 * 2560; time = 0.0724s; samplesPerSecond = 35354.2
11/23/2016 08:05:26:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.04929111 * 2560; err = 0.33359375 * 2560; time = 0.0724s; samplesPerSecond = 35374.8
11/23/2016 08:05:27:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.10560893 * 2560; err = 0.33867188 * 2560; time = 0.0725s; samplesPerSecond = 35310.8
11/23/2016 08:05:27:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.13%]: ce = 1.09147885 * 2560; err = 0.33945313 * 2560; time = 0.0726s; samplesPerSecond = 35263.2
11/23/2016 08:05:27:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.06739926 * 2560; err = 0.32460937 * 2560; time = 0.0725s; samplesPerSecond = 35313.8
11/23/2016 08:05:27:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.11190816 * 2560; err = 0.34648438 * 2560; time = 0.0725s; samplesPerSecond = 35300.6
11/23/2016 08:05:27:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.09175460 * 2560; err = 0.33046875 * 2560; time = 0.0725s; samplesPerSecond = 35290.4
11/23/2016 08:05:27:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.63%]: ce = 1.09300825 * 2560; err = 0.33515625 * 2560; time = 0.0725s; samplesPerSecond = 35298.7
11/23/2016 08:05:27:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08941239 * 2560; err = 0.33125000 * 2560; time = 0.0726s; samplesPerSecond = 35276.3
11/23/2016 08:05:27:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.06558937 * 2560; err = 0.32656250 * 2560; time = 0.0725s; samplesPerSecond = 35289.9
11/23/2016 08:05:27:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06327188 * 2560; err = 0.33046875 * 2560; time = 0.0725s; samplesPerSecond = 35303.0
11/23/2016 08:05:27: Finished Epoch[ 2 of 2]: [Training] ce = 1.11759343 * 81920; err = 0.34289551 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=2.32291s
11/23/2016 08:05:27: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech'

11/23/2016 08:05:27: Action "train" complete.


11/23/2016 08:05:27: ##############################################################################
11/23/2016 08:05:27: #                                                                            #
11/23/2016 08:05:27: # addLayer3 command (edit action)                                            #
11/23/2016 08:05:27: #                                                                            #
11/23/2016 08:05:27: ##############################################################################


11/23/2016 08:05:27: Action "edit" complete.


11/23/2016 08:05:27: ##############################################################################
11/23/2016 08:05:27: #                                                                            #
11/23/2016 08:05:27: # speechTrain command (train action)                                         #
11/23/2016 08:05:27: #                                                                            #
11/23/2016 08:05:27: ##############################################################################

11/23/2016 08:05:27: 
Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.scp ... 948 entries
total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/state.list
htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-SlaveTest\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/23/2016 08:05:28: 
Model has 29 nodes. Using GPU 0.

11/23/2016 08:05:28: Training criterion:   ce = CrossEntropyWithSoftmax
11/23/2016 08:05:28: Evaluation criterion: err = ClassificationError

11/23/2016 08:05:28: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

11/23/2016 08:05:28: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/23/2016 08:05:28: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/23/2016 08:05:28: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/23/2016 08:05:28: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/23/2016 08:05:28: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
11/23/2016 08:05:28: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
11/23/2016 08:05:28: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/23/2016 08:05:28: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/23/2016 08:05:28: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/23/2016 08:05:28: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/23/2016 08:05:28: Starting minibatch loop.
11/23/2016 08:05:28:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: ce = 4.04359151 * 2560; err = 0.84843750 * 2560; time = 0.1337s; samplesPerSecond = 19145.8
11/23/2016 08:05:28:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.52889660 * 2560; err = 0.60898438 * 2560; time = 0.1176s; samplesPerSecond = 21765.4
11/23/2016 08:05:28:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.03072845 * 2560; err = 0.56210938 * 2560; time = 0.1085s; samplesPerSecond = 23584.7
11/23/2016 08:05:28:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.67559968 * 2560; err = 0.46992187 * 2560; time = 0.1069s; samplesPerSecond = 23946.5
11/23/2016 08:05:28:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: ce = 1.49881510 * 2560; err = 0.43085937 * 2560; time = 0.1056s; samplesPerSecond = 24243.3
11/23/2016 08:05:28:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.45931898 * 2560; err = 0.41601563 * 2560; time = 0.1054s; samplesPerSecond = 24280.4
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.44767805 * 2560; err = 0.42460938 * 2560; time = 0.1055s; samplesPerSecond = 24269.3
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.36743058 * 2560; err = 0.40468750 * 2560; time = 0.1056s; samplesPerSecond = 24236.7
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: ce = 1.32114202 * 2560; err = 0.38632813 * 2560; time = 0.1056s; samplesPerSecond = 24232.3
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.28026190 * 2560; err = 0.37851563 * 2560; time = 0.1056s; samplesPerSecond = 24241.7
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31637035 * 2560; err = 0.37968750 * 2560; time = 0.1056s; samplesPerSecond = 24233.0
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27555159 * 2560; err = 0.37265625 * 2560; time = 0.1057s; samplesPerSecond = 24230.3
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: ce = 1.23651452 * 2560; err = 0.37265625 * 2560; time = 0.1056s; samplesPerSecond = 24247.0
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.25133961 * 2560; err = 0.38750000 * 2560; time = 0.1057s; samplesPerSecond = 24224.3
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.19939614 * 2560; err = 0.35976562 * 2560; time = 0.1054s; samplesPerSecond = 24285.4
11/23/2016 08:05:29:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.21946092 * 2560; err = 0.36757812 * 2560; time = 0.1053s; samplesPerSecond = 24313.8
11/23/2016 08:05:30:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: ce = 1.20994058 * 2560; err = 0.35937500 * 2560; time = 0.1056s; samplesPerSecond = 24251.8
11/23/2016 08:05:30:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.19457967 * 2560; err = 0.36757812 * 2560; time = 0.1057s; samplesPerSecond = 24212.4
11/23/2016 08:05:30:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.21383504 * 2560; err = 0.37031250 * 2560; time = 0.1056s; samplesPerSecond = 24240.1
11/23/2016 08:05:30:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.24982934 * 2560; err = 0.38242188 * 2560; time = 0.1056s; samplesPerSecond = 24236.7
11/23/2016 08:05:30:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: ce = 1.23493093 * 2560; err = 0.36445312 * 2560; time = 0.1056s; samplesPerSecond = 24242.7
11/23/2016 08:05:30:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.24105863 * 2560; err = 0.38203125 * 2560; time = 0.1056s; samplesPerSecond = 24231.4
11/23/2016 08:05:30:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.18162222 * 2560; err = 0.35000000 * 2560; time = 0.1056s; samplesPerSecond = 24244.7
11/23/2016 08:05:30:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.21420908 * 2560; err = 0.37226562 * 2560; time = 0.1056s; samplesPerSecond = 24245.6
11/23/2016 08:05:30:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: ce = 1.17194469 * 2560; err = 0.35703125 * 2560; time = 0.1056s; samplesPerSecond = 24249.8
11/23/2016 08:05:31:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.13737811 * 2560; err = 0.33671875 * 2560; time = 0.1055s; samplesPerSecond = 24272.3
11/23/2016 08:05:31:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.13527272 * 2560; err = 0.35468750 * 2560; time = 0.1056s; samplesPerSecond = 24237.8
11/23/2016 08:05:31:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.18904895 * 2560; err = 0.36015625 * 2560; time = 0.1056s; samplesPerSecond = 24241.3
11/23/2016 08:05:31:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: ce = 1.12368346 * 2560; err = 0.33125000 * 2560; time = 0.1057s; samplesPerSecond = 24229.3
11/23/2016 08:05:31:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.14844994 * 2560; err = 0.35312500 * 2560; time = 0.1056s; samplesPerSecond = 24239.4
11/23/2016 08:05:31:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.15147681 * 2560; err = 0.34765625 * 2560; time = 0.1056s; samplesPerSecond = 24243.3
11/23/2016 08:05:31:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.11755566 * 2560; err = 0.33867188 * 2560; time = 0.1056s; samplesPerSecond = 24253.7
11/23/2016 08:05:31: Finished Epoch[ 1 of 4]: [Training] ce = 1.40834099 * 81920; err = 0.40306396 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=3.57422s
11/23/2016 08:05:31: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.1'

11/23/2016 08:05:31: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/23/2016 08:05:31: Starting minibatch loop.
11/23/2016 08:05:31:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.23714249 * 5120; err = 0.37636719 * 5120; time = 0.1946s; samplesPerSecond = 26307.1
11/23/2016 08:05:32:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.29428655 * 5120; err = 0.38632813 * 5120; time = 0.1810s; samplesPerSecond = 28294.8
11/23/2016 08:05:32:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.23614025 * 5120; err = 0.37167969 * 5120; time = 0.1813s; samplesPerSecond = 28237.1
11/23/2016 08:05:32:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.14833986 * 5120; err = 0.35097656 * 5120; time = 0.1813s; samplesPerSecond = 28236.6
11/23/2016 08:05:32:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.15977380 * 5120; err = 0.35800781 * 5120; time = 0.1813s; samplesPerSecond = 28247.3
11/23/2016 08:05:32:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.12507026 * 5120; err = 0.34316406 * 5120; time = 0.1810s; samplesPerSecond = 28290.1
11/23/2016 08:05:33:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.12488975 * 5120; err = 0.35234375 * 5120; time = 0.1808s; samplesPerSecond = 28325.0
11/23/2016 08:05:33:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.09574978 * 5120; err = 0.34433594 * 5120; time = 0.1807s; samplesPerSecond = 28333.0
11/23/2016 08:05:33:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.08226356 * 5120; err = 0.32519531 * 5120; time = 0.1813s; samplesPerSecond = 28240.8
11/23/2016 08:05:33:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.09486881 * 5120; err = 0.34414062 * 5120; time = 0.1813s; samplesPerSecond = 28244.2
11/23/2016 08:05:33:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.08348842 * 5120; err = 0.32402344 * 5120; time = 0.1809s; samplesPerSecond = 28298.5
11/23/2016 08:05:33:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.06808197 * 5120; err = 0.33300781 * 5120; time = 0.1807s; samplesPerSecond = 28334.3
11/23/2016 08:05:34:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.07872466 * 5120; err = 0.33300781 * 5120; time = 0.1811s; samplesPerSecond = 28275.7
11/23/2016 08:05:34:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.20558164 * 5120; err = 0.37050781 * 5120; time = 0.1806s; samplesPerSecond = 28348.2
11/23/2016 08:05:34:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.08674875 * 5120; err = 0.33535156 * 5120; time = 0.1808s; samplesPerSecond = 28321.1
11/23/2016 08:05:34:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.06053896 * 5120; err = 0.32890625 * 5120; time = 0.1808s; samplesPerSecond = 28325.6
11/23/2016 08:05:34: Finished Epoch[ 2 of 4]: [Training] ce = 1.13635560 * 81920; err = 0.34858398 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=2.91236s
11/23/2016 08:05:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.2'

11/23/2016 08:05:34: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

11/23/2016 08:05:34: Starting minibatch loop.
11/23/2016 08:05:34:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.06907004 * 5120; err = 0.33300781 * 5120; time = 0.1825s; samplesPerSecond = 28057.4
11/23/2016 08:05:35:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.10118853 * 5120; err = 0.33613281 * 5120; time = 0.1811s; samplesPerSecond = 28272.9
11/23/2016 08:05:35:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.08803637 * 5120; err = 0.34042969 * 5120; time = 0.1815s; samplesPerSecond = 28212.0
11/23/2016 08:05:35:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.04793881 * 5120; err = 0.32304688 * 5120; time = 0.1821s; samplesPerSecond = 28113.2
11/23/2016 08:05:35:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.08630241 * 5120; err = 0.33359375 * 5120; time = 0.1817s; samplesPerSecond = 28183.7
11/23/2016 08:05:35:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.08354086 * 5120; err = 0.33183594 * 5120; time = 0.1813s; samplesPerSecond = 28242.8
11/23/2016 08:05:36:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.05851063 * 5120; err = 0.32832031 * 5120; time = 0.1817s; samplesPerSecond = 28183.7
11/23/2016 08:05:36:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07465391 * 5120; err = 0.33828125 * 5120; time = 0.1811s; samplesPerSecond = 28278.7
11/23/2016 08:05:36:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.10135151 * 5120; err = 0.35019531 * 5120; time = 0.1807s; samplesPerSecond = 28337.5
11/23/2016 08:05:36:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.01253480 * 5120; err = 0.31816406 * 5120; time = 0.1812s; samplesPerSecond = 28250.3
11/23/2016 08:05:36:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.02784589 * 5120; err = 0.32578125 * 5120; time = 0.1807s; samplesPerSecond = 28333.6
11/23/2016 08:05:36:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.05995610 * 5120; err = 0.33125000 * 5120; time = 0.1808s; samplesPerSecond = 28324.1
11/23/2016 08:05:37:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.06065592 * 5120; err = 0.33750000 * 5120; time = 0.1816s; samplesPerSecond = 28190.6
11/23/2016 08:05:37:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.08846674 * 5120; err = 0.34726563 * 5120; time = 0.1805s; samplesPerSecond = 28359.4
11/23/2016 08:05:37:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.02119488 * 5120; err = 0.31015625 * 5120; time = 0.1807s; samplesPerSecond = 28330.3
11/23/2016 08:05:37:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.02688694 * 5120; err = 0.32714844 * 5120; time = 0.1807s; samplesPerSecond = 28331.3
11/23/2016 08:05:37: Finished Epoch[ 3 of 4]: [Training] ce = 1.06300840 * 81920; err = 0.33200684 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=2.90322s
11/23/2016 08:05:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.3'

11/23/2016 08:05:37: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

11/23/2016 08:05:37: Starting minibatch loop.
11/23/2016 08:05:37:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02161010 * 5120; err = 0.32480469 * 5120; time = 0.1824s; samplesPerSecond = 28069.4
11/23/2016 08:05:38:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.00869745 * 4926; err = 0.31892002 * 4926; time = 0.2063s; samplesPerSecond = 23880.5
11/23/2016 08:05:38:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.01718310 * 5120; err = 0.31933594 * 5120; time = 0.1809s; samplesPerSecond = 28307.3
11/23/2016 08:05:38:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.03142096 * 5120; err = 0.32441406 * 5120; time = 0.1808s; samplesPerSecond = 28324.5
11/23/2016 08:05:38:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.02717013 * 5120; err = 0.32500000 * 5120; time = 0.1807s; samplesPerSecond = 28332.7
11/23/2016 08:05:38:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 0.99130001 * 5120; err = 0.31367187 * 5120; time = 0.1808s; samplesPerSecond = 28319.2
11/23/2016 08:05:39:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.00873585 * 5120; err = 0.32109375 * 5120; time = 0.1807s; samplesPerSecond = 28336.5
11/23/2016 08:05:39:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 0.99519168 * 5120; err = 0.30996094 * 5120; time = 0.1812s; samplesPerSecond = 28252.0
11/23/2016 08:05:39:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.96585133 * 5120; err = 0.31230469 * 5120; time = 0.1804s; samplesPerSecond = 28378.5
11/23/2016 08:05:39:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.98091812 * 5120; err = 0.30839844 * 5120; time = 0.1807s; samplesPerSecond = 28338.6
11/23/2016 08:05:39:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03417928 * 5120; err = 0.31875000 * 5120; time = 0.1808s; samplesPerSecond = 28325.0
11/23/2016 08:05:39:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.98718818 * 5120; err = 0.30781250 * 5120; time = 0.1808s; samplesPerSecond = 28318.6
11/23/2016 08:05:40:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.00111287 * 5120; err = 0.31171875 * 5120; time = 0.1806s; samplesPerSecond = 28345.1
11/23/2016 08:05:40:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.96719517 * 5120; err = 0.30078125 * 5120; time = 0.1806s; samplesPerSecond = 28352.1
11/23/2016 08:05:40:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.97385406 * 5120; err = 0.30410156 * 5120; time = 0.1805s; samplesPerSecond = 28361.9
11/23/2016 08:05:40:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.96321841 * 5120; err = 0.30664063 * 5120; time = 0.1806s; samplesPerSecond = 28345.7
11/23/2016 08:05:40: Finished Epoch[ 4 of 4]: [Training] ce = 0.99860761 * 81920; err = 0.31431885 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=2.93224s
11/23/2016 08:05:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20161123080511.14765\Speech\DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech'

11/23/2016 08:05:40: Action "train" complete.

11/23/2016 08:05:40: __COMPLETED__